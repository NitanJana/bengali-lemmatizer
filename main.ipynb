{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8adb347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might need to dockerize later\n",
    "\n",
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install translate\n",
    "# %pip install nltk\n",
    "# %pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44fe4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "import csv\n",
    "csv_filename = \"root_words.csv\"\n",
    "from translate import Translator\n",
    "translator = Translator(from_lang=\"bn\",to_lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f92e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCstring(X, Y):\n",
    "    m=len(X)\n",
    "    n=len(Y)\n",
    "    LCSuff = [[0 for k in range(n+1)] for l in range(m+1)]\n",
    "    result = 0\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if (i == 0 or j == 0):\n",
    "                LCSuff[i][j] = 0\n",
    "            elif (X[i-1] == Y[j-1]):\n",
    "                LCSuff[i][j] = LCSuff[i-1][j-1] + 1\n",
    "                result = max(result, LCSuff[i][j])\n",
    "            else:\n",
    "                LCSuff[i][j] = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "698fc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCsequence(X, Y):\n",
    "    # find the length of the strings\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "\n",
    "    # declaring the array for storing the dp values\n",
    "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
    "\n",
    "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion\n",
    "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
    "    and Y[0..j-1]\"\"\"\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0 :\n",
    "                L[i][j] = 0\n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                L[i][j] = L[i-1][j-1]+1\n",
    "            else:\n",
    "                L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    "    return L[m][n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2c80839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch suffix\n",
    "suffix=pd.read_excel('suffix_set.xlsx')\n",
    "class1_suffix=suffix[suffix['weight']==1]\n",
    "class2_suffix=suffix[suffix['weight']==2]\n",
    "class3_suffix=suffix[suffix['weight'].isin([1,3])]\n",
    "# hybrid_suffix=suffix[suffix['weight'].isin([3,4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d456995",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictnary=pd.read_excel('root_words.xlsx')\n",
    "def slice_dictnary(test_word):\n",
    "    # if len(test_word)>2 and not (class1_suffix['suffix'].isin([test_word[1]]).any()):\n",
    "    #     selector=2\n",
    "    # else:\n",
    "    #     selector=1\n",
    "    selector=1\n",
    "    if(test_word[0]=='উ'):\n",
    "        prefix1=test_word[:selector]\n",
    "        prefix2='ও'+test_word[1:selector]\n",
    "        sub_dictnary=dictnary[(dictnary['word'].str.match(f'{prefix1}+'))|(dictnary['word'].str.match(f'{prefix2}+'))]\n",
    "    elif(test_word[0]=='এ'):\n",
    "        prefix1=test_word[:selector]\n",
    "        prefix2='আ'+test_word[1:selector]\n",
    "        sub_dictnary=dictnary[(dictnary['word'].str.match(f'{prefix1}+'))|(dictnary['word'].str.match(f'{prefix2}+'))]\n",
    "    elif(test_word[0]=='ঐ'):\n",
    "        prefix1=test_word[:selector]\n",
    "        prefix2='ই'+test_word[1:selector]\n",
    "        sub_dictnary=dictnary[(dictnary['word'].str.match(f'{prefix1}+'))|(dictnary['word'].str.match(f'{prefix2}+'))]\n",
    "    else:\n",
    "        prefix=test_word[:selector]\n",
    "        sub_dictnary=dictnary[(dictnary['word'].str.match(f'{prefix}+'))]\n",
    "    return(sub_dictnary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cd38748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking(test_word):\n",
    "    global prediction_list\n",
    "    global sub_dictnary\n",
    "    if sub_dictnary['word'].isin([test_word]).any():\n",
    "        prediction_list.append(test_word)\n",
    "    else:\n",
    "        return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f927103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_with_translation(left_context,test_word,right_context):\n",
    "    root=[0.2,0.0,'']\n",
    "    translation_word=translator.translate(test_word).lower()\n",
    "    actual_window=left_context+\" \"+test_word+\" \"+right_context\n",
    "    translation_window=translator.translate(actual_window).lower()\n",
    "    while not root[2]:\n",
    "        for predicted_word in prediction_list:\n",
    "            error=(len(test_word)+len(predicted_word)-2*LCsequence(test_word,predicted_word))/(len(test_word)+len(predicted_word))\n",
    "            if error<=root[0]: \n",
    "                test_window=left_context+\" \"+predicted_word+\" \"+right_context\n",
    "                translation_testwindow=translator.translate(test_window).lower()\n",
    "                accurecy=LCsequence(translation_window,translation_testwindow)/len(translation_testwindow)\n",
    "#               print(translation_testwindow,accurecy)\n",
    "                if accurecy>root[1]:\n",
    "                    root[0]=error\n",
    "                    root[1]=accurecy\n",
    "                    root[2]=predicted_word\n",
    "                elif accurecy==root[1]:\n",
    "                    if(LCsequence(test_word,root[2])<=LCsequence(test_word,predicted_word)):\n",
    "                        root[0]=error\n",
    "                        root[1]=accurecy\n",
    "                        root[2]=predicted_word\n",
    "        if not root[2]:\n",
    "            root[0]+=0.1\n",
    "                \n",
    "    return(root[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be8939a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_root(target_suffix_set,test_word):\n",
    "    predicted_root=[test_word+suffix for suffix in target_suffix_set.suffix]\n",
    "    for i in predicted_root:\n",
    "        if checking(i):\n",
    "            continue\n",
    "    return predicted_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2c98b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_suffix(target_suffix,word):\n",
    "    final_suffix=''\n",
    "    #find actual suffix \n",
    "    #find longest suffix bettwen target_suffix that belongs at the end of given word \n",
    "    SL_word=[]\n",
    "    for i in target_suffix:\n",
    "        count=0\n",
    "        for j in range(-1,(-(len(i)+1)),-1):\n",
    "            if (word[j]==i[j]):\n",
    "                \n",
    "                count+=1\n",
    "            else:\n",
    "                break\n",
    "        if(count==len(i)):\n",
    "            final_suffix=i\n",
    "            SL_word.append(word.rstrip(final_suffix))\n",
    "    return(SL_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cbce401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dataset(context_word, root_word):\n",
    "    with open(csv_filename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        rows = [row for row in reader]\n",
    "\n",
    "        # Find the row with the root word and add the related word to it\n",
    "        found_root_word = False\n",
    "        for row in rows:\n",
    "            if row[0] == root_word and context_word not in row:\n",
    "                row.append(context_word)\n",
    "                found_root_word = True\n",
    "                break\n",
    "\n",
    "        # Write the modified list back to the CSV file\n",
    "        if found_root_word:\n",
    "            with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerows(rows)\n",
    "                print(f\"Added {context_word} as a related word for {root_word}\")\n",
    "        else:\n",
    "            print(f\"{root_word} not found in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bbbca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leematizer(context_word):\n",
    "    global prediction_list\n",
    "    container=[]\n",
    "    #print(sub_dictnary)\n",
    "    container.append(context_word)\n",
    "    print(\"input \",context_word)\n",
    "    if(context_word[0]=='উ'):\n",
    "        container.append('ও'+context_word[1:])\n",
    "        #print(container)\n",
    "    elif(context_word[0]=='এ'):\n",
    "        container.append('আ'+context_word[1:])\n",
    "    elif(context_word[0]=='ঐ'):\n",
    "        container.append('ই'+context_word[1:])\n",
    "    for word in container:\n",
    "        checking(word)\n",
    "        #checking for direct root\n",
    "        # if (class1_suffix['suffix'].isin([word[-1]]).any()):\n",
    "        #     #if there is any suffix of class 1 remove it\n",
    "        #     SL_word=remove_suffix(word[-1],word)\n",
    "        #     # SL_word denoted suffix_less_word\n",
    "        #     checking(SL_word)\n",
    "        #     predict_root(class1_suffix,SL_word)\n",
    "        index=[i in word for i  in class3_suffix.suffix]\n",
    "        # select class 3 suffix\n",
    "        if any(index):\n",
    "            # sort target suffix list in desc order of length\n",
    "            target_suffix=class3_suffix[index].suffix.tolist()\n",
    "            target_suffix.sort(key=len,reverse=True)\n",
    "            #print(target_suffix)\n",
    "            SL_word_set=remove_suffix(target_suffix,word)\n",
    "            if SL_word_set:\n",
    "                #remove suffix\n",
    "                #SL_word denoted suffix_less_word\n",
    "                for SL_word in SL_word_set:\n",
    "                    checking(SL_word)\n",
    "                    predict_root(class2_suffix,word) # select only class 1 suffix suffix that is in the word\n",
    "                    index=[]\n",
    "                    #print(SL_word)\n",
    "                    if len(SL_word)>1 and (class1_suffix['suffix'].isin([SL_word[-1]]).any()): #remove class 1 suffix suffix from end\n",
    "                        S_word=SL_word.rstrip(SL_word[-1])\n",
    "                    else:\n",
    "                        S_word=SL_word\n",
    "                    checking(S_word)\n",
    "                    #if Sl_word is root word declare it or checck it with other suffix one by one\n",
    "                    predict_root(class2_suffix,S_word)\n",
    "                    predicted_subword=predict_root(class1_suffix,S_word)\n",
    "                    #print(predicted_subword)\n",
    "                    #if it is a root word declear rootword else check is there any other suffix present\n",
    "                    #container.append(word)\n",
    "                    for i in predicted_subword:\n",
    "                        predict_root(class2_suffix,i)\n",
    "    prediction_list=[*set(prediction_list)]\n",
    "    #remove duplicate prediction \n",
    "    #print(prediction_list)\n",
    "    if(len(prediction_list)==1): #if predicttion list contain only one prediction declear as root\n",
    "        print(context_word,'--->',prediction_list[0])       \n",
    "        add_to_dataset(context_word, prediction_list[0])\n",
    "    elif(len(prediction_list)>1): #if more than one check using meaning\n",
    "        root=checking_with_translation(left_context,context_word,right_context)\n",
    "        print(context_word,'--->',root)\n",
    "        add_to_dataset(context_word, prediction_list[0])\n",
    "    else:\n",
    "        print(context_word,\"not in database\")\n",
    "    #     root=[0,'']\n",
    "    #     for dict_word in sub_dictnary.word:\n",
    "    #         lcs=LCsequence(dict_word,context_word)\n",
    "    #         if(lcs>root[0]):\n",
    "    #             root[0]=lcs\n",
    "    #             root[1]=dict_word\n",
    "    #     print(context_word,'--->',root[1])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca2c5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[]\n",
    "#sentence1=\"ছাত্রজীবন মানব জীবনের প্রস্তুতিকাল। ছাত্রজীবনের ভিত্তির উপর ধীরে ধীরে মানবজীবনের কর্ম কৃতিত্বের সৌধটি গড়ে ওঠে। এই ভিত্তি সুদৃঢ় হবে, ভবিষ্যতে জীবন ও তত বলিষ্ঠ এবং সমৃদ্ধ হবে। মানব জীবনের ভিত্তি সুদৃঢ় করতে হলে ছাত্রজীবনে যত্নবান হতে হবে।তাই ছাত্রজীবনে লেখাপড়াও খেলাধুলার সঙ্গে সঙ্গে যেমন শরীর ও চরিত্র গঠন করতে হবে, তেমনি জগৎ ও জীবনের বহু বিচিত্র কর্মধারার সঙ্গে পরিচয় সাধন করতে হবে। এই পরিচয় সাধনের সূত্রই ছাত্রজীবনে সমাজকল্যাণ অথবা সমাজসেবা।\"\n",
    "#sentence2=\"সভ্যতার প্রথম উন্মেষ কালে আগুন আবিষ্কারের পরই সমাজ গঠন বোধকরি মানব সভ্যতার অন্যতম অবদান। তারপর থেকে সভ্যতার অগ্রগতি ও ক্রমবিকাশের সঙ্গে সঙ্গে গোষ্ঠীবদ্ধ মানুষ কতগুলি অলিখিত নিয়ম কানুন ও রীতিনীতি সূত্রে একে অন্যের সঙ্গে পরস্পর গাঁতা হয়ে পৃথিবীর এক এক অঞ্চলে একত্রে বসবাস করতে আরম্ভ করলো। এই ভাবেই একদিন সুসভ্য মানুষের সমাজ গড়ে উঠলো। সমাজের উদ্ভবের প্রথম দিন থেকেই মানুষ সমাজ সেবায় প্রয়োজন অনুভব করে। আজ সভ্যতার চরম উৎকর্ষের দিনেও মানব সমাজে এই সেবা ও সহযোগিতার প্রয়োজন এতটুকু কমেনি। সুতরাং সমাজসেবা বলতে সমাজের অন্তর্গত মানুষের সেবা ও কল্যাণকেই বোঝায়।\"\n",
    "#sentence3=\"সমাজসেবার প্রয়োজন সব দেশে থাকলেও ভারতবর্ষের মতো দরিদ্র উন্নয়নশীল বিশাল দেশে এর গুরুত্ব সমাধি। ১০০ কোটি জন অধ্যুষিত এই বিশাল দেশের কোটি কোটি মানুষ নিদারুণ দুঃখ দুর্দশা ও অভাব-অনটনে নিপীড়িত। দেশের অনেক মানুষই আজও নিরক্ষরতার নিবিড় অন্ধকারে নিমজ্জিত। এর ওপর আছে প্রাকৃতিক বিপর্যয় ঝড়-ঝঞ্ঝা খরা, বন্যা, ভূমিকম্প, ও দুর্ভিক্ষ মহামারীর তান্ডব লীলা। বলা বাহুল্য, এদেশে এসব সমস্যার ও দুর্যোগ এর মোকাবিলা করার প্রাথমিক দায়িত্ব দেশের সরকারের বিশেষত আমাদের দেশে যখন জনকল্যাণমুখী গণতান্ত্রিক রাষ্ট্র প্রতিষ্ঠিত। কিন্তু কী অর্থে ,কি সামর্থ্যে এই বিরাট সমস্যার সমাধান করা রাষ্ট্রশক্তির একার পক্ষে কখনোই সম্ভব নয়। সেই দিক দিয়ে এদেশের সমাজ সেবার গুরুত্ব অপরিসীম।\"\n",
    "#sentence4= \"সুপ্রাচীন কাল থেকেই ভারতীয় উপমহাদেশ অর্থনৈতিক সমৃদ্ধি ও সাংস্কৃতিক ঐতিহ্যের জন্য সুপরিচিত। ঐতিহাসিক সিন্ধু সভ্যতা এই অঞ্চলেই গড়ে উঠেছিল। ইতিহাসের বিভিন্ন পর্বে এখানেই স্থাপিত হয়েছিল বিশালাকার একাধিক সাম্রাজ্য। নানা ইতিহাস-প্রসিদ্ধ বাণিজ্যপথ এই অঞ্চলের সঙ্গে বিশ্বের অন্যান্য সভ্যতার বাণিজ্যিক ও সাংস্কৃতিক সম্পর্ক রক্ষা করত। হিন্দু, বৌদ্ধ, জৈন ও শিখ—বিশ্বের এই চার ধর্মের উৎসভূমি ভারত। খ্রিস্টীয় প্রথম সহস্রাব্দে জরথুস্ত্রীয় ধর্ম (পারসি ধর্ম), ইহুদি ধর্ম, খ্রিস্টধর্ম ও ইসলাম ধর্ম এ দেশে প্রবেশ করে, ও ভারতীয় সংস্কৃতিতে বিশেষ প্রভাব বিস্তার করে। অষ্টাদশ শতাব্দীর প্রথমার্ধ থেকে ব্রিটিশ ইস্ট ইন্ডিয়া কোম্পানি ধীরে ধীরে ভারতীয় ভূখণ্ডের অধিকাংশ অঞ্চল নিজেদের শাসনাধীনে আনতে সক্ষম হয়। উনবিংশ শতাব্দীর মধ্যভাগে এই দেশ পুরোদস্তুর একটি ব্রিটিশ উপনিবেশে পরিণত হয়ে ওঠে। অতঃপর, এক সুদীর্ঘ স্বাধীনতা সংগ্রামের মধ্য দিয়ে ১৯৪৭ সালে ভারত একটি স্বতন্ত্র রাষ্ট্ররূপে আত্মপ্রকাশ করে। ১৯৫০ সালে সংবিধান প্রণয়নের মাধ্যমে ভারত একটি সার্বভৌম গণতান্ত্রিক প্রজাতন্ত্রে পরিণত হয়।\"\n",
    "#sentence5=\"এদেশের সমাজসেবার সমস্যাটির যেমন গরিষ্ঠ তেমনি এর ক্ষেত্রটি ও বহুদূর বিস্তৃত। এই বিশাল ক্ষেত্রে সমাজ সেবায় অংশগ্রহণ করবে কে বা কারা? অবশ্য সরকারের ভূমিকায় এতে অগ্রগণ্য ,কিন্তু দেশের অসংখ্য জনহিতকর সেবা প্রতিষ্ঠান গুলির ভূমিকা ও এতে নগণ্য নয়। সমাজসেবামূলক এই প্রতিষ্ঠান গুলির মধ্যে রামকৃষ্ণ মিশন, ভারত সেবাশ্রম, মাড়োয়ারি রিলিফা সোসাইটি, রেড ক্রস, সেন্ট জনস্ অ্যাম্বুলেন্স প্রভৃতি উল্লেখযোগ্য এবং তাদের অবদান তাদের অকুণ্ঠ ও নিরলস জনসেবা প্রশংসনীয়। তবে সমাজসেবার বিশাল ক্ষেত্র ও বিপুল গুরুত্বের তুলনায় এই সেবা উল্লেখযোগ্য হলেও পর্যাপ্ত নয়।সমাজসেবার দায়িত্ব পালন ও গুরু ভার বহনের জন্য তাই প্রয়োজন বৃহত্তর শক্তির।\"\n",
    "#sentence6=\"পাঠিকা ঠাকুরানি নিজ গুণে ক্ষমা করবেন। মাতালের গল্প ছাড়া আমার গতি নেই।\"\n",
    "#sentence7=\"তাই শুধু স্বাভাবিকভাবে নয়, প্রয়োজনের কারণে ও দেশের সুবিশাল ছাত্রসমাজের সুবিপুল কর্মশক্তির ওপর সমাজসেবার অংশগ্রহণের কথা এসে পড়ে। এখানে ও সমাজ সেবায় ছাত্র দের সম্পর্ক। ছাত্রসমাজ শুধু শক্তি মান নয়,সমাজসেবার কাছে তারা যোগ্য ও উপযুক্ত ও বটে। কারণ সমাজ সেবার জন্য যে সময় এবং শ্রম এর প্রয়োজন, আগ্রহ থাকলেও নানান সমস্যায় নিত্য বিব্রত কর্মজীবী সংসারী মানুষ তা দিতে পারে না। আপাতত দৃষ্টিতে অসম্ভব হলেও দেশের ছাত্রসমাজই সমাজসেবার মহান দায়িত্ব পালনে সময় ও শ্রম নিয়োগ করতে সক্ষম।অসীম প্রাণশক্তিতে উদ্বেল, অফুরন্ত উৎসাহে চঞ্চল, উচ্ছৃসিত আনন্দে ভরপুর তাজা তরুণ ছাত্র সমাজ তাই যেকোনো দুঃসাহসী কাজে নিঃস্বার্থ পরোপকারিতায় ঝাঁপিয়ে পড়ার জন্য সদাই উন্মুখ। লেখাপড়া ও খেলাধুলা করেও ছাত্রদের যে উৎসাহ উদ্বৃত থাকে তাকেই সমাজসেবার কাজে নিয়োজিত করতে হবে। ছাত্রজীবনে সমাজসেবার এই গুরুত্ব ও প্রয়োজনীয়তার কথা বিবেচনা করেই আমাদের মাধ্যমিক স্তরের শিক্ষাক্রমে সমাজসেবাকে পাঠ্য ও আচরণীয় বিষয় হিসেবে গ্রহণ করা হয়েছে\"\n",
    "# sentence8=\"তাই শুধু স্বাভাবিকভাবে নয়, প্রয়োজনের কারণে ও দেশের সুবিশাল ছাত্রসমাজের সুবিপুল কর্মশক্তির ওপর সমাজসেবার অংশগ্রহণের কথা এসে পড়ে। এখানে ও সমাজ সেবায় ছাত্র দের সম্পর্ক। ছাত্রসমাজ শুধু শক্তি মান নয়,সমাজসেবার কাছে তারা যোগ্য ও উপযুক্ত ও বটে। কারণ সমাজ সেবার জন্য যে সময় এবং শ্রম এর প্রয়োজন, আগ্রহ থাকলেও নানান সমস্যায় নিত্য বিব্রত কর্মজীবী সংসারী মানুষ তা দিতে পারে না। আপাতত দৃষ্টিতে অসম্ভব হলেও দেশের ছাত্রসমাজই সমাজসেবার মহান দায়িত্ব পালনে সময় ও শ্রম নিয়োগ করতে সক্ষম।অসীম প্রাণশক্তিতে উদ্বেল, অফুরন্ত উৎসাহে চঞ্চল, উচ্ছৃসিত আনন্দে ভরপুর তাজা তরুণ ছাত্র সমাজ তাই যেকোনো দুঃসাহসী কাজে নিঃস্বার্থ পরোপকারিতায় ঝাঁপিয়ে পড়ার জন্য সদাই উন্মুখ। লেখাপড়া ও খেলাধুলা করেও ছাত্রদের যে উৎসাহ উদ্বৃত থাকে তাকেই সমাজসেবার কাজে নিয়োজিত করতে হবে। ছাত্রজীবনে সমাজসেবার এই গুরুত্ব ও প্রয়োজনীয়তার কথা বিবেচনা করেই আমাদের মাধ্যমিক স্তরের শিক্ষাক্রমে সমাজসেবাকে পাঠ্য ও আচরণীয় বিষয় হিসেবে গ্রহণ করা হয়েছে\"\n",
    "sentence9=\"অক্ষর জ্ঞান যার নেই তাকেই নিরক্ষর বলা যেতে পারে। নিরক্ষর মানুষ জীবনের সবদিক থেকেই পিছিয়ে নিরক্ষরতা বহু ক্ষেত্রে মানুষের সার্বিক আত্মিক বিকাশের অন্তরায়। নিরক্ষরতার অভিশাপে অভিশপ্ত ব্যক্তি সাধারণতঃ নিজের অথবা সমাজের জন্য কিছু করে দেখাতে পারেনা। নিরক্ষরতার পরিণতি হলো নিরবতার অনুসরণ করা অর্থাৎ প্রত্যেক ক্ষেত্রে পিছিয়ে পড়া। নিরক্ষর মানুষ পৃথিবীকে নিজেকে পরিবেশকে লাঞ্ছনাকে ও শোষণকে জানতে পারেনা। রবীন্দ্রনাথ ঠাকুর বলেছেন মানুষের অন্ধত্বের মত নিরক্ষরতা এই দুর্ভাগ্য দেশের হতভাগ্য জনগণের সর্বাপেক্ষা নিষ্ঠুরতম অভিশাপ। নিরক্ষরতার স্বরূপকে বোঝার জন্য আমরা আমাদের দেশ ভারতকে বুঝলেই চলবে- যেখানে মোট জনসংখ্যার এক-তৃতীয়াংশ নিরক্ষর। এই নিরক্ষতাকে দূর করা একান্ত প্রয়োজনীয়।\"\n",
    "# sentences=sentence9.replace(\"-\",\" \")\n",
    "\n",
    "sentences=sentence9.split(\"।\")\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens.extend(nltk.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d973f685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['অক্ষর', 'জ্ঞান', 'যার', 'নেই', 'তাকেই', 'নিরক্ষর', 'বলা', 'যেতে', 'পারে', 'নিরক্ষর', 'মানুষ', 'জীবনের', 'সবদিক', 'থেকেই', 'পিছিয়ে', 'নিরক্ষরতা', 'বহু', 'ক্ষেত্রে', 'মানুষের', 'সার্বিক', 'আত্মিক', 'বিকাশের', 'অন্তরায়', 'নিরক্ষরতার', 'অভিশাপে', 'অভিশপ্ত', 'ব্যক্তি', 'সাধারণতঃ', 'নিজের', 'অথবা', 'সমাজের', 'জন্য', 'কিছু', 'করে', 'দেখাতে', 'পারেনা', 'নিরক্ষরতার', 'পরিণতি', 'হলো', 'নিরবতার', 'অনুসরণ', 'করা', 'অর্থাৎ', 'প্রত্যেক', 'ক্ষেত্রে', 'পিছিয়ে', 'পড়া', 'নিরক্ষর', 'মানুষ', 'পৃথিবীকে', 'নিজেকে', 'পরিবেশকে', 'লাঞ্ছনাকে', 'ও', 'শোষণকে', 'জানতে', 'পারেনা', 'রবীন্দ্রনাথ', 'ঠাকুর', 'বলেছেন', 'মানুষের', 'অন্ধত্বের', 'মত', 'নিরক্ষরতা', 'এই', 'দুর্ভাগ্য', 'দেশের', 'হতভাগ্য', 'জনগণের', 'সর্বাপেক্ষা', 'নিষ্ঠুরতম', 'অভিশাপ', 'নিরক্ষরতার', 'স্বরূপকে', 'বোঝার', 'জন্য', 'আমরা', 'আমাদের', 'দেশ', 'ভারতকে', 'বুঝলেই', 'চলবে', 'যেখানে', 'মোট', 'জনসংখ্যার', 'একতৃতীয়াংশ', 'নিরক্ষর', 'এই', 'নিরক্ষতাকে', 'দূর', 'করা', 'একান্ত', 'প্রয়োজনীয়']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Define a regular expression \n",
    "bengali_pattern = re.compile(r\"[a-zA-Z0-9০১২৩৪৫৬৭৮৯।(),–.’\\u200c/`‘'-;%]\")\n",
    "\n",
    "# Remove Bengali digits from the tokens\n",
    "words = [bengali_pattern.sub(\"\", token) for token in tokens]\n",
    "\n",
    "# Print the result\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f07eb843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "অক্ষর -> অক্ষর\n",
      "জ্ঞান -> জ্ঞান\n",
      "যার -> যে\n",
      "নেই -> নেই\n",
      "তাকেই -> তারা\n",
      "নিরক্ষর -> নিরক্ষর\n",
      "বলা -> বলা\n",
      "যেতে -> যেতে\n",
      "পারে -> পরা\n",
      "নিরক্ষর -> নিরক্ষর\n",
      "মানুষ -> মানুষ\n",
      "জীবনের -> জীবন\n",
      "সবদিক -> সবদিক\n",
      "থেকেই -> থাকা\n",
      "input  পিছিয়ে\n",
      "পিছিয়ে not in database\n",
      "নিরক্ষরতা -> নিরক্ষর\n",
      "বহু -> বহু\n",
      "ক্ষেত্রে -> ক্ষেত্র\n",
      "মানুষের -> মানুষ\n",
      "input  সার্বিক\n",
      "সার্বিক not in database\n",
      "আত্মিক -> আত্মা\n",
      "বিকাশের -> বিকাশ\n",
      "input  অন্তরায়\n",
      "অন্তরায় not in database\n",
      "input  নিরক্ষরতার\n",
      "নিরক্ষরতার not in database\n",
      "অভিশাপে -> অভিশাপ\n",
      "input  অভিশপ্ত\n",
      "অভিশপ্ত not in database\n",
      "input  ব্যক্তি\n",
      "ব্যক্তি not in database\n",
      "input  সাধারণতঃ\n",
      "সাধারণতঃ not in database\n",
      "নিজের -> নিজ\n",
      "অথবা -> অথবা\n",
      "সমাজের -> সমাজ\n",
      "জন্য -> জন্য\n",
      "কিছু -> কিছু\n",
      "করে -> করা\n",
      "দেখাতে -> দেখা\n",
      "input  পারেনা\n",
      "পারেনা not in database\n",
      "input  নিরক্ষরতার\n",
      "নিরক্ষরতার not in database\n",
      "পরিণতি -> পরিণত\n",
      "হলো -> হওয়া\n",
      "input  নিরবতার\n",
      "নিরবতার ---> নিরবতা\n",
      "নিরবতা not found in the dataset\n",
      "অনুসরণ -> অনুসরণ\n",
      "করা -> করা\n",
      "অর্থাৎ -> অর্থাৎ\n",
      "প্রত্যেক -> প্রত্যেক\n",
      "ক্ষেত্রে -> ক্ষেত্র\n",
      "input  পিছিয়ে\n",
      "পিছিয়ে not in database\n",
      "পড়া -> পড়া\n",
      "নিরক্ষর -> নিরক্ষর\n",
      "মানুষ -> মানুষ\n",
      "পৃথিবীকে -> পৃথিবী\n",
      "নিজেকে -> নিজ\n",
      "পরিবেশকে -> পরিবেশ\n",
      "লাঞ্ছনাকে -> লাঞ্ছনা\n",
      "শোষণকে -> শোষণ\n",
      "জানতে -> জানা\n",
      "input  পারেনা\n",
      "পারেনা not in database\n",
      "রবীন্দ্রনাথ -> রবীন্দ্রনাথ\n",
      "ঠাকুর -> ঠাকুর\n",
      "বলেছেন -> বলা\n",
      "মানুষের -> মানুষ\n",
      "অন্ধত্বের -> অন্ধত্ব\n",
      "মত -> মত\n",
      "নিরক্ষরতা -> নিরক্ষর\n",
      "এই -> এই\n",
      "দুর্ভাগ্য -> দুর্ভাগ্য\n",
      "দেশের -> দেশ\n",
      "হতভাগ্য -> হতভাগ্য\n",
      "জনগণের -> জনগণ\n",
      "সর্বাপেক্ষা -> সর্বাপেক্ষা\n",
      "input  নিষ্ঠুরতম\n",
      "নিষ্ঠুরতম not in database\n",
      "অভিশাপ -> অভিশাপ\n",
      "input  নিরক্ষরতার\n",
      "নিরক্ষরতার not in database\n",
      "স্বরূপকে -> স্বরূপ\n",
      "বোঝার -> বোঝা\n",
      "জন্য -> জন্য\n",
      "আমরা -> আমরা\n",
      "আমাদের -> আমরা\n",
      "দেশ -> দেশ\n",
      "ভারতকে -> ভারত\n",
      "input  বুঝলেই\n",
      "বুঝলেই not in database\n",
      "চলবে -> চল\n",
      "input  যেখানে\n",
      "যেখানে not in database\n",
      "মোট -> মোট\n",
      "জনসংখ্যার -> জনসংখ্যা\n",
      "input  একতৃতীয়াংশ\n",
      "একতৃতীয়াংশ not in database\n",
      "নিরক্ষর -> নিরক্ষর\n",
      "এই -> এই\n",
      "input  নিরক্ষতাকে\n",
      "নিরক্ষতাকে not in database\n",
      "দূর -> দূর\n",
      "করা -> করা\n",
      "একান্ত -> একান্ত\n",
      "প্রয়োজনীয় -> প্রয়োজন\n"
     ]
    }
   ],
   "source": [
    "for i in words:\n",
    "    if len(i)<2:\n",
    "        words.remove(i)\n",
    "for word in words:\n",
    "    search_word = word\n",
    "\n",
    "    with open(csv_filename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        found_root_word = False\n",
    "        #check if the word exists in dataset\n",
    "        for row in reader:\n",
    "            if len(row) > 0 and row[0] == search_word:\n",
    "                print(f\"{search_word} -> {row[0]}\")\n",
    "                found_root_word = True\n",
    "            elif len(row) > 0 and search_word in row:\n",
    "                print(f\"{search_word} -> {row[0]}\")\n",
    "                found_root_word = True\n",
    "                \n",
    "        if not found_root_word:\n",
    "\n",
    "            if words.index(word)==0:\n",
    "                left_context=''\n",
    "                right_context=words[words.index(word)+1]\n",
    "            elif words.index(word)==len(words)-1:\n",
    "                left_context=words[words.index(word)-1]\n",
    "                right_context=''\n",
    "            else:\n",
    "                left_context=words[words.index(word)-1]\n",
    "                right_context=words[words.index(word)+1]\n",
    "            sub_dictnary=slice_dictnary(word)\n",
    "            if not sub_dictnary.empty:\n",
    "                prediction_list=[]\n",
    "                leematizer(word)    \n",
    "            else :\n",
    "                print (word,\"not in database\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10729446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  উঠলো\n",
      "উঠলো ---> ওঠা\n",
      "ওঠা not found in the dataset\n",
      "he told me\n",
      "he told me\n",
      "1.0\n",
      "0.0\n",
      "he said amen.\n",
      "0.5384615384615384\n",
      "0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "prediction_list=[]\n",
    "container=[]\n",
    "sub_dictnary=slice_dictnary('উঠলো')\n",
    "leematizer('উঠলো')\n",
    "translation_window=translator.translate('সে আমাকে বলেছিল').lower()\n",
    "print(translation_window)\n",
    "for translation_testword in ['আমি', 'আম']:\n",
    "    translation_testword=translator.translate('সে '+translation_testword+' বলেছিল').lower()\n",
    "    print(translation_testword)\n",
    "    print(LCsequence(translation_window,translation_testword)/len(translation_testword))\n",
    "#     print(LCsequence(translation_window,translation_testword,len(translation_window),len(translation_testword)))\n",
    "#    print(LCsequence(translation_window,translation_testword,len(translation_window),len(translation_testword))/len(translation_testword))\n",
    "#     print(LCsequence(translation_window,translation_testword,len(translation_window),len(translation_testword))/abs(len(translation_testword)-len(translation_window)))\n",
    "    print(abs(len(translation_testword)-len(translation_window))/LCsequence(translation_window,translation_testword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40fff1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  গায়ের\n",
      "গায়ের not in database\n",
      "the color of his skin.\n",
      "the color he sings.\n",
      "0.8421052631578947\n",
      "0.1875\n",
      "color of hers\n",
      "0.8461538461538461\n",
      "0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "prediction_list=[]\n",
    "container=[]\n",
    "leematizer('গায়ের')\n",
    "\n",
    "translation_window=translator.translate('তার গায়ের রঙ ').lower()\n",
    "print(translation_window)\n",
    "for translation_testword in ['গাওয়া', 'গা']:\n",
    "    translation_testword=translator.translate('তারে '+translation_testword+' রঙ').lower()\n",
    "    print(translation_testword)\n",
    "# print(LCsequence(translation_window,translation_testword,len(translation_window),len(translation_testword)))\n",
    "    print(LCsequence(translation_window,translation_testword)/len(translation_testword))\n",
    "#     print(LCsequence(translation_window,translation_testword,len(translation_window),len(translation_testword))/abs(len(translation_testword)-len(translation_window)))\n",
    "    print(abs(len(translation_testword)-len(translation_window))/LCsequence(translation_window,translation_testword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5b40831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the color he sings.\n",
      "0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "translation_testword=translator.translate('তারে গাওয়া রঙ').lower()\n",
    "translation_window='the color of his skin'\n",
    "if translation_testword:\n",
    "    print(translation_testword)\n",
    "print(abs(len(translation_testword)-len(translation_window))/LCsequence(translation_window,translation_testword))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
